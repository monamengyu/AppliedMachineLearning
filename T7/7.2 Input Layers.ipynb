{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydjJTPw0Yp1A"
   },
   "source": [
    "## Input layers in Neural Networks\n",
    "\n",
    "### Introduction\n",
    "A *neural network* can be thought of as a pipeline that transforms raw data into predictions. The *input layer* is the first step of that pipeline—like a front door where your data enters before it’s processed further. Specifically, the *input layer*:\n",
    "\n",
    "- Defines the shape (or structure) of the data entering the network.  \n",
    "- Ensures that all following layers receive data in a consistent format.\n",
    "\n",
    "If you’re working with images, the network needs details about each image’s size and colour channels (like red, green, and blue). If you have text data, the network needs to know about the length of each sequence of words or tokens. For spreadsheet data, it needs the number of columns (features) for each row (sample).\n",
    "\n",
    "The *input shape* is essential because it:\n",
    "\n",
    "- Helps the network recognise the data format - is the data a simple list of numbers, a grid of pixels, or a sequence of time steps?  \n",
    "- Ensures that later layers know how many inputs to expect - each layer needs this information to set up its internal parameters correctly.\n",
    "\n",
    "If the input shape is wrong, the model might not work at all (due to mismatched sizes) or could produce strange results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JHw4ly7Yp1C"
   },
   "source": [
    "### The Input layer in Keras/TensorFlow\n",
    "\n",
    "In Keras (part of TensorFlow), there are two main ways to let your network know what shape of data to expect. The first is to *use the `input_shape` argument in the very first layer*, which is common if you’re building a Sequential model. For example:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # More layers...\n",
    "])\n",
    "```\n",
    "\n",
    "Here, `input_shape=(28, 28, 1)` tells the model that each sample is an image of 28×28 pixels with 1 colour channel (grayscale). You don’t include the batch size (e.g. 64, if that’s how many samples you want to process at once) in the `input_shape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 11058,
     "status": "ok",
     "timestamp": 1746024704329,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "4l6M6BY2Yp1D",
    "outputId": "8ddca991-6120-473d-bc04-aec54b4e73dd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Further layers...\n",
    "])\n",
    "\n",
    "model.summary()  # Just to illustrate the model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayPro66xYp1E"
   },
   "source": [
    "- `Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))`:  \n",
    "This line creates a 2D convolutional layer with 32 filters, each filter being 3×3 in size. The layer uses the ReLU activation function, which means it sets negative outputs to zero and keeps positive outputs as they are. The `input_shape=(28, 28, 1)` tells Keras that each individual sample is a 28×28 image with 1 colour channel (e.g. grayscale).\n",
    "\n",
    "- `model = Sequential([...])`:\n",
    "Wrapping your layers in a `Sequential` model, tells Keras to stack these layers in a simple chain—each layer’s output becomes the next layer’s input. In this example, the `Conv2D` layer is the first layer; after it, you can add more layers (like another convolution, a pooling layer, or a fully connected layer).\n",
    "\n",
    "- `model.summary()`:  \n",
    "Calling `model.summary()` provides a quick, table-based breakdown of your network. It shows each layer, its output shape, and the number of parameters (weights and biases). This is a handy way to confirm that your layers are connected as intended and that you haven’t made any shape mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiuSo_XJYp1E"
   },
   "source": [
    "Using a dedicated `Input` layer is particularly useful when you want more flexibility in building your model. This approach is common in what’s called the *Functional API* (or in subclassed models). Instead of stacking layers in a simple list (as you would in a Sequential model), you explicitly define how data flows from an input, through a series of transformations (layers), and out to a result.\n",
    "\n",
    "Below is an example showing how to create and connect an `Input` layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1746024704438,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "vIq5zijgYp1E",
    "outputId": "f7ffd481-2d36-47c9-d8b6-e3016c1cac67"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer by specifying the shape of each sample\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "\n",
    "# Pass the input through a convolutional layer\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "# You can add more layers here...\n",
    "\n",
    "# Define the final model by specifying the inputs and outputs\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCJdkIOeYp1F"
   },
   "source": [
    "- `inputs = Input(shape=(28, 28, 1))`:  \n",
    "This tells Keras that each incoming sample is an image of size 28×28 pixels with 1 colour channel.\n",
    "\n",
    "- `x = Conv2D(32, (3, 3), activation='relu')(inputs)`:  \n",
    "When we apply this layer to `inputs`, we form a “connection” from the input to the convolution operation. The `Conv2D` layer learns filters that detect specific patterns in the image.\n",
    "\n",
    "- `model = Model(inputs=inputs, outputs=x)`:  \n",
    "Instead of simply stacking layers one after the other, you’re explicitly linking the input to the output. This makes it easier to build complex architectures, such as multi-input or multi-output models, or models that have branching or skipping connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0uCFdEYYp1F"
   },
   "source": [
    "#### Shapes versus Batches\n",
    "\n",
    "When using Keras, you typically *don’t* include the *batch size* (how many samples you process in one go) in the `input_shape` setting. For example, if you feed the network 64 images at a time, each image is still described by `(28, 28, 1)`. Under the hood, Keras handles the extra dimension for the batch, effectively treating all 64 images as `(64, 28, 28, 1)`. But in your code, you only need `(28, 28, 1)`.\n",
    "\n",
    "The reason for this is flexibility: you may want to change how many samples you process at a time depending on your hardware or specific needs. Omitting the batch size lets your model adapt to different batch sizes while keeping the shape of each individual sample clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky0cM9UuYp1F"
   },
   "source": [
    "### Exploring different Input shapes\n",
    "\n",
    "When building a neural network, it’s important to give your model a clear understanding of how your data is arranged. The term *input shape* refers to the dimensions and structure of each individual sample fed into the network. For example, if you’re working with spreadsheet-like data, your input might be a single row of numbers. If you’re dealing with images, the input must specify the height and width in pixels, along with the number of colour channels (e.g. red, green, and blue). If you have time-based or language data, you might need a shape that reflects a sequence of values or tokens.\n",
    "\n",
    "Each of these formats: tabular data, images, sequences etc. requires a different way of telling the network, “Here’s how a single example looks.” Defining this *input shape*, ensures that all the subsequent layers can arrange themselves properly and figure out how to handle what you’re feeding in. If the network expects a certain shape but receives something else, it may not run correctly or could produce unexpected results. Understanding and setting the input shape is therefore one of the most critical steps in designing a neural network.\n",
    "\n",
    "#### Tabular data (1D Input)\n",
    "When your data can be arranged like rows and columns in a spreadsheet, you’re dealing with *tabular data*. Each row is a *sample*, and each column is a *feature*. For example, suppose you have:\n",
    "\n",
    "- *1,000 samples* (rows in your spreadsheet)  \n",
    "- *10 features* per sample (columns in your spreadsheet)\n",
    "\n",
    "In this scenario, each sample is essentially a collection of 10 numbers, think of them as 10 different measurements or properties. Therefore, the *input shape* for the network would be `(10,)`, meaning each example is represented by a simple list (or vector) of length 10.\n",
    "\n",
    "This might include data points like a person’s age, height, and weight, or numerical readings from various sensors. The neural network learns patterns from these features that help it predict an outcome, whether that’s a category (for classification) or a numeric value (for regression). Ensuring the network knows each sample has 10 values gives it a clear window into how the data is structured, enabling it to process each feature correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1746024704594,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "As9QgG1dYp1G",
    "outputId": "2d511ebd-5c8b-43ba-ab99-34d036814581"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),  # 10 features\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja1X8owmYp1G"
   },
   "source": [
    "- `Dense(32, activation='relu', input_shape=(10,))`:  \n",
    "This line creates a fully connected (Dense) layer with 32 neurons. The `input_shape=(10,)` tells Keras that each input sample is a vector of 10 features. The ReLU activation function is applied, which transforms the inputs to the layer in a non-linear fashion by setting negative values to zero (more on activations functions later).\n",
    "\n",
    "- `Dense(16, activation='relu')`:  \n",
    "The next layer is another Dense layer with 16 neurons. It takes the output of the previous layer as its input and also uses ReLU as its activation function.\n",
    "\n",
    "- `Dense(1, activation='sigmoid')`:  \n",
    "The final layer is a Dense layer with a single neuron, applying the sigmoid activation function. This configuration is typical for binary classification, as the sigmoid function outputs a value between 0 and 1, representing the probability of one of the two classes.\n",
    "\n",
    "- `model.summary()`:  \n",
    "Calling this function prints a summary of the model’s architecture, including each layer's output shape and the number of trainable parameters. This helps you verify that your network is constructed as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69x4Hkj1Yp1G"
   },
   "source": [
    "#### Image data (2D + colour channel)\n",
    "\n",
    "When your data is made up of images, you need to think in terms of *height*, *width*, and *channels*. For instance, a black-and-white (grayscale) image has just one channel, while a colour image typically has three (for red, green, and blue). In practice, this means:\n",
    "\n",
    "- A 64×64 colour image has the shape `(64, 64, 3)`.  \n",
    "- A 28×28 grayscale image has the shape `(28, 28, 1)`.\n",
    "\n",
    "Here, *64×64* or *28×28* describe the height and width in pixels, and the final number (such as *3* or *1*) represents the number of colour channels. Think of it like looking at a picture with different layers: the red layer, the green layer, and the blue layer. Each pixel in the image is assigned values for each layer, which the neural network learns to interpret.\n",
    "\n",
    "So if you feed an image into your network, Keras needs to know these dimensions up front to set up its internal layers correctly (especially *Conv2D* layers). If your images don’t match the specified shape, the network won’t be able to process them. For example, if you tried to feed a 64×64 image into a model expecting a 28×28 input, it would cause an error because the shapes don’t line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1746024704674,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "fb8TRrgdYp1G",
    "outputId": "943819f6-aa73-4dca-8aca-e7faa9b67f51"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10-class classification\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycygBZ5-Yp1G"
   },
   "source": [
    "- `Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(64, 64, 3))`:  \n",
    "This line creates a 2D convolutional layer that processes images. It uses 32 filters with a size of 3×3 and applies the ReLU activation function. The `input_shape=(64, 64, 3)` tells Keras that each input sample is a 64×64 pixel colour image, with 3 channels (red, green, and blue).\n",
    "\n",
    "- `Flatten()`:  \n",
    "The Flatten layer transforms the multi-dimensional output of the convolutional layer into a one-dimensional array. This allows the subsequent Dense layers to process the data as a vector rather than a grid.\n",
    "\n",
    "- `Dense(64, activation='relu')`:  \n",
    "This Dense layer takes the flattened vector and outputs 64 values, applying the ReLU activation function. It serves as a fully connected layer that starts learning higher-level features from the previous layers.\n",
    "\n",
    "- `Dense(10, activation='softmax')`:  \n",
    "The final Dense layer outputs 10 values, one for each class in a 10-class classification problem. The softmax activation function converts these outputs into probabilities that sum to 1, indicating the likelihood of each class.\n",
    "\n",
    "- `model.summary()`:  \n",
    "Calling this function prints a detailed summary of the model architecture, including the output shape of each layer and the number of trainable parameters, allowing you to verify that the network is structured as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8RoAI7YYp1G"
   },
   "source": [
    "### Sequence data (Time or Words)\n",
    "\n",
    "Sequence data comes into play when each sample extends over multiple time steps or tokens. Unlike a single snapshot of features (as in tabular data) or a grid of pixels (as in images), sequences unfold over time or along a series of words, characters, or events.\n",
    "\n",
    "#### Time Series\n",
    "Imagine you have a sensor taking readings every hour for 100 hours. If each reading is just a single number, then one sample representing one continuous time window is basically a list of 100 numbers. In Keras, you would represent that as `(100, 1)`:  \n",
    "- `100` indicates the length of the sequence (the number of time steps).  \n",
    "- `1` indicates that each time step has only one measurement (one feature).\n",
    "\n",
    "You can think of it like a line graph where each point on the line is a new reading from the sensor. Because these readings come in order, you need a neural network structure (like an LSTM or other recurrent layers) that can learn patterns across the entire sequence, rather than just looking at each point in isolation. If you’ve ever plotted values on a graph over time, that’s essentially your time-series data—except now, a neural network is reading that sequence to predict future values or classify the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1746024704791,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "NjKnAeVcYp1H",
    "outputId": "5fef01ff-072a-4300-c4db-1cd3ec6a35ec"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(100, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FRLJE8DYp1H"
   },
   "source": [
    "- `LSTM(32, input_shape=(100, 1))`:  \n",
    "   This line creates an LSTM (Long Short-Term Memory) layer with 32 units. The `input_shape=(100, 1)` tells Keras that each sample is a sequence of 100 time steps, with 1 feature per time step. The LSTM layer is designed to capture patterns and dependencies across the sequence.\n",
    "\n",
    "- `Dense(1)`:  \n",
    "   This Dense layer follows the LSTM layer and consists of a single neuron. It takes the output from the LSTM and transforms it into a single value. This configuration is typically used for tasks like regression or binary classification, where only one output is needed.\n",
    "\n",
    "- `model.summary()`:  \n",
    "   Calling this function prints a detailed overview of the model’s architecture, including the shape of the output at each layer and the number of parameters that the model needs to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0H_6nrIYp1H"
   },
   "source": [
    "#### Text (Word Embeddings)\n",
    "\n",
    "When dealing with natural language, words are often converted into numerical representations before they’re fed into a neural network. These numerical representations are called *embeddings*. Think of each embedding as a vector (a list of numbers) that captures some semantic or contextual information about the word.\n",
    "\n",
    "For instance, if you have a sentence of 10 words, and each word is represented by a 50-dimensional embedding, then one sentence (one sample) has the shape `(10, 50)`. The number `10` corresponds to how many words are in the sentence (also known as the sequence length), and `50` corresponds to the size of the embedding for each word.\n",
    "\n",
    "Why do this? Well, neural networks can’t directly understand text in its raw form. Embeddings translate words into numbers in such a way that words with similar meanings have vectors that are closer together. By providing the network with these vectors, you enable it to learn relationships between words and potentially understand context, rather than just seeing text as a sequence of unrelated symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1746024704869,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "-zzIoXCDYp1H",
    "outputId": "19b54e1e-1a9e-459d-98c1-d67c0363a6af"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(10, 50))\n",
    "x = LSTM(32)(inputs)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJXLeFFKYp1H"
   },
   "source": [
    "- `inputs = Input(shape=(10, 50))`:  \n",
    "   This line defines the input layer using Keras's functional API. It tells Keras that each sample is a sequence of 10 timesteps, and each timestep has 50 features. This is useful for handling data like sentences (with word embeddings) or time series with multiple features per time step.\n",
    "\n",
    "- `x = LSTM(32)(inputs)`:  \n",
    "   The input is then passed into an LSTM layer with 32 units. The LSTM processes the sequence data, capturing temporal dependencies and patterns across the 10 timesteps, and outputs a 32-dimensional vector that summarises the information from the sequence.\n",
    "\n",
    "- `outputs = Dense(1, activation='sigmoid')(x)`:  \n",
    "   The 32-dimensional output from the LSTM is sent to a Dense layer with a single neuron. The sigmoid activation function is applied, which compresses the output into a value between 0 and 1. This configuration is typically used for binary classification problems.\n",
    "\n",
    "- `model = Model(inputs, outputs)`:  \n",
    "   This line creates the Keras Model, linking the defined input layer directly to the output layer. It allows for more flexible model architectures, making it easier to construct complex networks with multiple inputs and outputs or with branching connections.\n",
    "\n",
    "- `model.summary()`:  \n",
    "   Calling `model.summary()` prints a detailed summary of the model’s architecture, including each layer's type, output shape, and the number of parameters. This helps in verifying that the model is set up correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1XX_EjEYp1H"
   },
   "source": [
    "### What have we learnt?\n",
    "\n",
    "The *input layer* is the first stop your data makes inside a neural network. You can think of it as the entrance hall: it welcomes the data and ensures everything is in the right format. Whether you are working with images, text, or traditional tables of numbers, the input layer needs to know the shape or structure of your data. This could be a simple row of numbers if you are dealing with spreadsheets, or multiple channels of colour if you are dealing with images.\n",
    "\n",
    "The *input shape* itself depends on what type of data you have. For tabular data, each sample is often just a list of features. For images, you typically specify height, width, and any colour channels. If your data is a time series or text, you might define the sequence length and how many values appear at each step. In each case, the goal is to match how your raw data is organised in the real world.\n",
    "\n",
    "When using Keras, you usually omit the *batch size* (the number of samples you process at once) from the shape. So instead of writing `(64, 28, 28, 1)` for 64 images of size 28×28, you just write `(28, 28, 1)`. Getting the input shape correct is critical; if it’s wrong, the model may fail to run or could produce unpredictable outputs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
