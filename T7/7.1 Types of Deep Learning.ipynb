{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4424ea",
   "metadata": {
    "id": "8d4424ea"
   },
   "source": [
    "## Deep Learning models in TensorFlow\n",
    "### Introduction\n",
    "We will explore different types of neural network models and how they can be applied to image classification using the *MNIST* dataset again, a well-known collection of handwritten digits (0–9). This will give us a chance to understand how various deep learning architectures work and when each might be useful.\n",
    "\n",
    "We will introduce four types of neural network models, starting from the simplest (Perceptron) to more advanced models like LSTMs. We will explain how we evaluate model performance and understand whether a model is good enough.  We will then visualise model performance using metrics like *Accuracy*.  \n",
    "\n",
    "Experimenting with each of these models, will enable us to develop a practical understanding of how deep learning can be applied to different types of data and problems, from simple classification to more complex, sequential prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea94a6",
   "metadata": {
    "id": "9cea94a6"
   },
   "source": [
    "We start by setting a common number of epochs for each of our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6996c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746020822954,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "8f6996c7"
   },
   "outputs": [],
   "source": [
    "epochs = 10  # shortened to 10 for demonstration purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31cb9e",
   "metadata": {
    "id": "0d31cb9e"
   },
   "source": [
    "### Perceptron (Single-Layer Neural Network)\n",
    "A *Perceptron* is the simplest kind of neural network and is often seen as the starting point for understanding more complex models. It was one of the earliest ideas in artificial intelligence and is mainly used to tell the difference between two groups of data, for example, whether a message is spam or not. The Perceptron does this by trying to draw a straight line (or boundary) that separates one type of data from another.\n",
    "\n",
    "To understand how a perceptron makes decisions, we can break it down into a few key parts:\n",
    "\n",
    "- *Inputs* – These are the features or values the model looks at, like pixel brightness in an image.  \n",
    "- *Weights* – Each input is multiplied by a number that tells the model how important it is.  \n",
    "- *Bias* – A small adjustment that shifts the decision boundary to improve accuracy.  \n",
    "- *Weighted sum* – All the weighted inputs and the bias are added together to get a score.  \n",
    "- *Activation function* – This function checks whether the score is high enough to trigger a certain output (usually 0 or 1).  \n",
    "\n",
    "So, in essence, the perceptron adds up the inputs (each scaled by its weight), checks the total score, and decides which class the data belongs to During training, the perceptron learns by comparing its prediction to the correct answer and adjusting the weights if it gets it wrong. This happens repeatedly with many examples until the model improves. The key steps are:\n",
    "\n",
    "- Make a prediction using the current weights.  \n",
    "- Compare it to the correct label.  \n",
    "- Adjust the weights slightly if the prediction is wrong (using a learning rate to control the step size).  \n",
    "\n",
    "This learning process helps reduce errors and move the decision boundary in the right direction. While perceptrons are useful for learning the basics of neural networks, they have some clear limitations:\n",
    "\n",
    "- Only works for linearly separable data – it can’t handle cases where a straight line won’t do the job (like XOR problems).  \n",
    "- Too simple for complex patterns – it struggles with anything beyond basic classification.  \n",
    "- Rigid activation function – the step function doesn’t allow for shades of grey in predictions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8386165",
   "metadata": {},
   "source": [
    "### Install Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d5637",
   "metadata": {},
   "source": [
    "### Load the data (create)\n",
    "We create our own synthetic dataset representing the AND logic gate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset for the AND logic gate\n",
    "# Input combinations: each row is a pair of binary inputs [x1, x2]\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "# Target outputs: results of the AND operation on the inputs\n",
    "Y = np.array([0, 0, 0, 1])  # Only [1, 1] gives 1 in an AND gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909f9ac",
   "metadata": {},
   "source": [
    "### Model\n",
    "We will create our own Python class from scratch to represent the Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915561e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746020822969,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "5915561e",
    "outputId": "5fafb21b-14a4-47c7-cf82-58a75e1a23bb"
   },
   "outputs": [],
   "source": [
    "# Define a Perceptron class from scratch\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=10):\n",
    "        # Initialise weights and bias to zero\n",
    "        self.weights = np.zeros(input_size)  # One weight per input feature\n",
    "        self.bias = 0\n",
    "        self.lr = learning_rate              # Learning rate controls step size\n",
    "        self.epochs = epochs                 # Number of times to loop through the data\n",
    "\n",
    "    def activation(self, z):\n",
    "        # Step activation function: returns 1 if z ≥ 0, otherwise 0\n",
    "        return 1 if z >= 0 else 0\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Compute the linear combination of inputs and weights + bias\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        # Apply the step function to produce binary output\n",
    "        return self.activation(z)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # Loop through the training data multiple times (epochs)\n",
    "        for epoch in range(self.epochs):\n",
    "            for xi, target in zip(X, y):         # For each input-output pair\n",
    "                prediction = self.predict(xi)    # Predict current output\n",
    "                error = target - prediction      # Calculate prediction error\n",
    "\n",
    "                # Update rule for weights and bias (only if there's an error)\n",
    "                self.weights += self.lr * error * xi\n",
    "                self.bias += self.lr * error\n",
    "\n",
    "            # Print weights and bias at the end of each epoch\n",
    "            print(f\"Epoch {epoch+1} | Weights: {self.weights} | Bias: {self.bias}\")\n",
    "\n",
    "# Create and train the Perceptron on the AND gate\n",
    "model = Perceptron(input_size=2)\n",
    "model.train(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb6ead",
   "metadata": {},
   "source": [
    "#### Predict\n",
    "We can now make predictions on some test values from our training data. This is just for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b294ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the model's predictions on all inputs\n",
    "print(\"\\nPredictions:\")\n",
    "for xi in X:\n",
    "    print(f\"{xi} => {model.predict(xi)}\")  # Show input and predicted output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca3ea7",
   "metadata": {
    "id": "d4ca3ea7"
   },
   "source": [
    "### Multilayer Perceptron (MLP)\n",
    "\n",
    "The basic *perceptron* is like a simple decision-maker. It looks at inputs (like exam scores or pixels in an image) and tries to make a yes/no decision. But it's quite limited, it can only handle very simple patterns, like drawing a straight line to split things into categories.\n",
    "\n",
    "To go beyond that, we use something called a *Multilayer Perceptron* (MLP). Think of it like building a team of decision-makers, where each one passes information to the next. This stacked approach lets the model understand much more complicated patterns, even ones that can't be separated with a simple line. We construct a Multilayer Perceptron as follows:\n",
    "\n",
    "- *Hidden layers*: \n",
    "These are extra layers of \"mini-decision-makers\" placed between the input and the final output. Each layer helps the model spot different features or patterns in the data. More layers mean more brainpower to figure things out.\n",
    "\n",
    "- *Activation functions*: \n",
    "These are like switches that tell each layer how to respond. Two common ones are:\n",
    "  - *ReLU*: Think of this as a filter that lets through positive numbers and blocks the negatives. It helps the model learn quickly and avoid problems during training (more on this later).\n",
    "  - *Softmax*: Used at the end when we’re picking from several categories (like identifying handwritten digits). It turns the output into a list of probabilities, so we can pick the most likely answer.\n",
    "\n",
    "- *Optimiser*: \n",
    "This is the algorithm that helps the model get better during training. One popular choice is *Adam*, it’s smart and automatically fine-tunes itself, so the model improves faster and more reliably.\n",
    "\n",
    "When we stack layers and use activation functions, an MLP can go far beyond what a single perceptron can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9edee5",
   "metadata": {},
   "source": [
    "### Breast Cancer dataset\n",
    "The *Breast Cancer dataset* you are using comes from the `scikit-learn` library and is a well-known benchmark dataset in machine learning, particularly for binary classification tasks. It contains data collected from digitised images of breast tissue masses, where each sample is described by a set of features computed from the image, such as the radius, texture, perimeter, area, and smoothness of the cells. These features aim to capture the key physical characteristics of the cell nuclei, which help distinguish between benign (non-cancerous) and malignant (cancerous) tumours.\n",
    "\n",
    "The dataset includes 569 samples and 30 numerical features, along with a binary target label indicating whether the tumour is malignant or benign. It is small, well-structured, and presents a meaningful real-world medical classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc857b",
   "metadata": {
    "id": "aafc857b"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1fe4b",
   "metadata": {
    "executionInfo": {
     "elapsed": 4985,
     "status": "ok",
     "timestamp": 1746020827955,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "ccb1fe4b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert data to a pandas DataFrame \n",
    "# to print an overview of the data (we won't use this for training etc.)\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Add the target (label) as a new column\n",
    "df['target'] = data.target\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7OIiLaR_fZaL",
   "metadata": {
    "id": "7OIiLaR_fZaL"
   },
   "source": [
    "### Resampling\n",
    "\n",
    "We split our data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lW6X0hGCfcw8",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1746020828001,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "lW6X0hGCfcw8"
   },
   "outputs": [],
   "source": [
    "X = data.data\n",
    "Y = data.target  # 0 = malignant, 1 = benign\n",
    "\n",
    "# Ensure input data are NumPy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "seed = 7\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a39130",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We apply a standard scaler to show how you might preprocess the features, but you may want to go further depending on the data you are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c87aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HuDSL7f0fr7Y",
   "metadata": {
    "id": "HuDSL7f0fr7Y"
   },
   "source": [
    "We have some data with our features and labels extracted and scaled, and so we can now pass it to our model and train.\n",
    "\n",
    "In the code below, we create a MLP using TensorFlow's `Sequential` model, which lets us stack layers one after another in a straightforward way. The model starts with an input layer that takes in the training features. This is followed by two hidden layers: the first has 32 neurons, and the second has 16. Both use the `ReLU` (Rectified Linear Unit) activation function, which helps the model learn quickly and effectively by allowing it to focus on patterns that matter. The final layer has just one neuron, using a sigmoid activation function to produce an output between `0` and `1`, essentially a probability that we can interpret as a \"yes\" or \"no\" answer for binary classification.\n",
    "\n",
    "After building the model, we compile it with an `adam` optimiser, which is a clever algorithm that automatically adjusts the weights in the network during training to reduce errors. We use a loss function called binary cross-entropy, which is standard for yes/no tasks, and we ask the model to keep track of its accuracy as it learns. The model is then trained over a number of cycles, known as ``epochs`, during which it sees the training data again and again, gradually improving its predictions. \n",
    "\n",
    "After training, we ask the model to make predictions on unseen test data and evaluate its performance using several metrics: accuracy (how often it was right), mean absolute error (how far off its predictions were on average), and mean squared error (a similar measure that penalises larger mistakes more heavily).\n",
    "\n",
    "A single perceptron is simple and limited to straightforward decisions, whereas, a multilayer perceptron like the one in this code is much more powerful. It can uncover hidden patterns in data and make better decisions, especially when the problem isn’t easily solved with a single dividing line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e496a9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23106,
     "status": "ok",
     "timestamp": 1746020851109,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "5e496a9a",
    "outputId": "68cbf6c6-29ad-4722-ac95-98a162edb5c8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build a Multilayer Perceptron (MLP) model using the Sequential API\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),   # Define the input shape (number of features)\n",
    "    Dense(32, activation='relu'),       # First hidden layer with 32 neurons and ReLU activation\n",
    "    Dense(16, activation='relu'),       # Second hidden layer with 16 neurons and ReLU activation\n",
    "    Dense(1, activation='sigmoid')      # Output layer with 1 neuron for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with optimiser, loss function, and metrics to track\n",
    "model.compile(\n",
    "    optimizer=Adam(),                   # Adam optimiser for efficient training\n",
    "    loss='binary_crossentropy',         # Loss function for binary classification tasks\n",
    "    metrics=['accuracy']                # Track accuracy during training and evaluation\n",
    ")\n",
    "\n",
    "# Train the model using training data, and validate on test data after each epoch\n",
    "history = model.fit(\n",
    "    X_train, Y_train,                   # Input features and labels for training\n",
    "    epochs=epochs,                      # Number of training epochs\n",
    "    validation_data=(X_test, Y_test)    # Validation data for monitoring performance\n",
    ")\n",
    "\n",
    "# Use the model to predict probabilities for the test data\n",
    "y_pred_probs = model.predict(X_test).flatten()   # Outputs a probability for each sample; flatten to 1D array\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)        # Convert probabilities to 0 or 1 based on a 0.5 threshold\n",
    "\n",
    "# Print evaluation metrics to assess model performance\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, y_pred):.4f}\")               # Classification accuracy\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(Y_test, y_pred_probs):.4f}\")  # Average error in predicted probabilities\n",
    "print(f\"Mean Squared Error: {mean_squared_error(Y_test, y_pred_probs):.4f}\")    # Squared error in predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e59ffb",
   "metadata": {},
   "source": [
    "Looking at the above output, training progressed very smoothly, with the network quickly learning to distinguish between the two activities. In the first epoch it jumped from essentially chance‐level (≈42 % training accuracy) to already 75 % on the validation set, while loss dropped from about 0.82 down to 0.58. By epoch 3 it surpassed 90 % validation accuracy with loss around 0.30, and by epoch 5 it was consistently in the mid-90s.\n",
    "\n",
    "By the final epoch (10), training accuracy reached about 97 % with a loss of 0.11, and validation accuracy climbed to roughly 96.5 % with a loss near 0.10—indicating very strong generalisation and minimal overfitting. A held-out evaluation confirmed this, yielding an accuracy of 96.5 %, a mean absolute error of approximately 0.077, and a mean squared error of about 0.027. Overall, the model performs very well on this binary sequence-classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6J3rpHdrwSK",
   "metadata": {
    "id": "u6J3rpHdrwSK"
   },
   "source": [
    "#### Plot Train loss and Validation loss\n",
    "We plot the train and validation loss to see how the model trained each epoch.\n",
    "\n",
    "The first graph shows the loss over time, on the vertical axis. We plot how large the errors were, and on the horizontal axis, we plot the number of epochs. We include two lines: one for the training loss, showing how well the model is doing on the data it’s learning from, and one for the validation loss, showing how well it’s generalising to new data. Ideally, both lines should go down over time, but if the training loss keeps improving while the validation loss gets worse, it’s a sign the model is overfitting, that is, it’s memorising the training data rather than learning general patterns.\n",
    "\n",
    "The second graph shows the accuracy over time, again with one line for training accuracy and one for validation accuracy. On the vertical axis, we have the proportion of correct predictions, ranging from 0 (completely wrong) to 1 (perfectly correct), and again, epochs are on the horizontal axis. This plot gives us a clear picture of whether the model is genuinely improving in terms of making correct predictions or if it’s simply becoming overconfident on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac6d94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1746020851674,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "12ac6d94",
    "outputId": "0ace5d2f-a362-4ae3-8f56-3a3c596d74b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss and accuracy\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plotting Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot training loss values stored in history.history['loss']\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "\n",
    "# Plot validation loss values stored in history.history['val_loss']\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title(\"Loss over Epochs\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Plot training accuracy values stored in history.history['accuracy']\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "\n",
    "# Plot validation accuracy values stored in history.history['val_accuracy']\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the spacing between subplots so labels/titles don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10298f27",
   "metadata": {},
   "source": [
    "### Predict\n",
    "Let's also see what the actual prediction look like. We use the trained model to predict probabilities on the test set, which gives values between 0 and 1 for each test sample, with a 1 meaning the patient has cancer, and a 0 meaning they are clear or have no indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ad246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values between 0 and 1 for each test sample\n",
    "y_pred_probs = model.predict(X_test).flatten()\n",
    "\n",
    "# Convert probabilities to binary class predictions (0 or 1)\n",
    "# Any value > 0.5 is classified as class 1 (benign), else class 0 (malignant)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Print 10 predicted class label\n",
    "for i in range(10):\n",
    "    print(\"Predicted class labels:\", y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50441a93",
   "metadata": {
    "id": "50441a93"
   },
   "source": [
    "### Feedforward Neural Network (FNN)\n",
    "\n",
    "A *Feedforward Neural Network* (often simply called an FNN) is one of the most common types of neural networks. It is called \"feedforward\" because the information flows in only one direction, from the input layer, through one or more hidden layers, and finally to the output layer. There are no loops or feedback connections, meaning each input is processed and passed straight through the network.\n",
    "\n",
    "FNNs are an extension of the basic *perceptron* we looked at earlier. Instead of just one layer of neurons, a feedforward network includes one or more *hidden layers*, each made up of many neurons that transform the input data in increasingly complex ways. This allows the network to learn patterns that are much more advanced than a single-layer perceptron could ever handle.\n",
    "\n",
    "Each neuron in a layer is connected to every neuron in the next layer, and the network learns by adjusting the *weights* on these connections based on how well it predicts the correct answer. This learning happens over multiple rounds, or *epochs*, gradually improving the network's performance.\n",
    "\n",
    "FNNs are used for a wide variety of tasks, such as recognising handwritten digits, predicting house prices, or classifying emails as spam or not spam. They are especially useful when the data doesn’t have any particular order or sequence, for example, static images or tabular data, because they treat every input as independent.\n",
    "\n",
    ">*MLP versus FNN*:\n",
    ">\n",
    "> A FNN sounds a lot like an MLP, the key difference is that a FNN is a broader term that refers to any neural network where information flows from input to output, without any loops or feedback. MLPs are a type of FNN. But not all FNNs are MLPs. For example, a *Convolutional Neural Network* (CNN) used for image data is also a type of feedforward network, but it uses convolutional layers instead of just fully connected layers. >An MLP, in contrast, uses just *Dense* layers throughout.\n",
    ">\n",
    "\n",
    "Although they don’t remember past information, feedforward networks are a powerful and versatile starting point for most deep learning problems. We will use the same *Breast Cancer dataset* we used in the MLP example, for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ae247",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2795,
     "status": "ok",
     "timestamp": 1746020854469,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "b76ae247",
    "outputId": "2264f2cf-4954-4564-880b-bcb0e1748613"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules from the TensorFlow Keras library\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build a Feedforward Neural Network (FNN) for tabular data\n",
    "model_fnn = Sequential([\n",
    "    # First hidden layer:\n",
    "    Input(shape=(X_train.shape[1],)),   # Define the input shape (number of features)\n",
    "\n",
    "    # Second hidden layer: 64 neurons and ReLU activation\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    # Output layer: 1 neuron (since it's a binary classification problem)\n",
    "    # Sigmoid activation function to get a probability between 0 and 1\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Specify parameters and compile the model:\n",
    "#  Adam optimiser, a popular choice for gradient-based optimisation\n",
    "#  Binary crossentropy is the loss function for binary classification\n",
    "#  Accuracy is the performance metric to track during training\n",
    "model_fnn.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model on the training data (X_train, Y_train)\n",
    "# For n epochs and validate on the test data (X_test, Y_test).\n",
    "history_FNN = model_fnn.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, Y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a16120",
   "metadata": {},
   "source": [
    "In this run the model learns very quickly and generalises exceptionally well. It starts already strong in epoch 1, with training accuracy at about 84 % (loss 0.47) and validation accuracy near 89 % (loss 0.28). By epoch 3 it's above 92 % on validation with loss down around 0.16, and by epoch 5 validation accuracy climbs to nearly 95 % with loss roughly 0.12. Training accuracy keeps improving and reaches about 98 % by epoch 10, while validation accuracy plateaus at around 96.5 % and validation loss steadily falls to about 0.085. Validation performance continues to improve (or at least doesn’'t degrade)as well as training loss, suggests minimal overfitting, and overall this configuration provides reliable binary classification on the sequence data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TE4XzqHSrtyC",
   "metadata": {
    "id": "TE4XzqHSrtyC"
   },
   "source": [
    "#### Plot Train loss and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf814c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1746020854869,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "51bf814c",
    "outputId": "53bbf79e-51f6-4e46-e9e8-8ce886d5bc37"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure to plot training and validation metrics side by side\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Create the first subplot (1 row, 2 columns, position 1)\n",
    "\n",
    "# Plot training and validation loss values over epochs\n",
    "plt.plot(history_FNN.history['loss'], label='Train Loss')        # Training loss\n",
    "plt.plot(history_FNN.history['val_loss'], label='Val Loss')      # Validation loss\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# Add legend for better readability\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)  # Create the second subplot (position 2)\n",
    "\n",
    "# Plot training and validation accuracy values over epochs\n",
    "plt.plot(history_FNN.history['accuracy'], label='Train Accuracy')        # Training accuracy\n",
    "plt.plot(history_FNN.history['val_accuracy'], label='Val Accuracy')      # Validation accuracy\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Adjust spacing between subplots and display the plots\n",
    "plt.tight_layout()  # Prevent subplots from overlapping\n",
    "plt.show()      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04cf73",
   "metadata": {
    "id": "4f04cf73"
   },
   "source": [
    "### Recurrent Neural Network (RNN)\n",
    "\n",
    "A *Recurrent Neural Network (RNN)* is a special type of neural network designed to work with *sequential data*, that is, data where the order of observations matters. Unlike standard feedforward networks, RNNs include a form of memory that allows them to use information from earlier time steps when making predictions. This makes them well-suited for tasks such as language modelling, time series prediction, and sensor-based activity recognition.\n",
    "\n",
    "In this case, we’re using the *Heterogeneity Human Activity Recognition (HHAR)* dataset, which contains motion sensor data (accelerometer readings in x, y, and z axes) collected from smart devices as users perform different physical activities, such as walking, climbing stairs, or biking. These activities produce distinct motion patterns that can be recognised by a neural network, but only if we consider the *sequence* of sensor readings over time, not just isolated measurements.\n",
    "\n",
    "To model this data with an RNN, we first split the continuous sensor data into *fixed-length sequences* (for example, 50 time steps per sample). Each sequence is treated as a mini time series, with shape:\n",
    "\n",
    "`samples × time_steps × features`  \n",
    "\n",
    "In our case, that's something like:  \n",
    "\n",
    "`(number of segments, 50 readings, 3 sensor channels)`\n",
    "\n",
    "This allows the RNN to process the signal one time step at a time, learning to detect patterns that evolve across the full window, such as acceleration spikes during running, or periodic motion during walking. By maintaining an internal state that gets updated over time, the RNN can \"remember\" key moments earlier in the sequence to help it classify the entire activity.\n",
    "\n",
    "While RNNs can sometimes struggle to remember long-term dependencies, they’re an excellent starting point for sequential modelling and help us build toward more powerful variants like LSTMs and GRUs, which are designed to retain information across longer spans of time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544500d",
   "metadata": {
    "id": "7544500d"
   },
   "source": [
    "### Accelerometer and Gyro mobile phone dataset\n",
    "This dataset contains motion sensor readings collected from the *accelerometer* and *gyroscope* of a mobile phone, designed to support experiments in *activity recognition*, *sensor data analysis*, and *human motion modelling*.\n",
    "\n",
    "The data was gathered from a smartphone placed in a user's front pocket while performing a variety of physical activities. These include common everyday movements such as walking, climbing stairs, and standing still. The sensors recorded 3-axis acceleration and angular velocity at a fixed sampling rate, creating time series data that reflects changes in movement and orientation over time.\n",
    "\n",
    "Each sample is labelled according to the type of activity being performed, making this a labelled, supervised learning dataset suitable for classification tasks. Researchers can use it to explore techniques in time-series preprocessing, feature extraction, and machine learning, particularly in the context of mobile or wearable sensor data.\n",
    "\n",
    "This dataset is especially relevant for developing and testing models for real-time activity recognition, fall detection (elderly), fitness tracking, or general-purpose mobile sensing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iPwb1slUr5ER",
   "metadata": {
    "id": "iPwb1slUr5ER"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f099a80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1746020855448,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "6f099a80",
    "outputId": "aa263d0d-648c-4102-d76f-54b4a102f180"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Download the ZIP file\n",
    "url = \"http://www.archive.ics.uci.edu/static/public/755/accelerometer+gyro+mobile+phone+dataset.zip\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Unzip contents into memory\n",
    "with zipfile.ZipFile(io.BytesIO(r.content)) as zip_ref:\n",
    "    zip_ref.extractall(\"activity_data\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"activity_data/accelerometer_gyro_mobile_phone_dataset.csv\")\n",
    "\n",
    "# Preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3866b",
   "metadata": {
    "id": "add3866b"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b207745",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746020855462,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "6b207745"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Remove empty or NaN rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Features and label\n",
    "features = ['accX', 'accY', 'accZ', 'gyroX', 'gyroY', 'gyroZ']\n",
    "X = df[features]\n",
    "Y = df['Activity']\n",
    "\n",
    "# Scale the feature values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Combine back into dataframe to keep order\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "df_scaled['Activity'] = Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb553d",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf5e5f",
   "metadata": {
    "id": "a4bf5e5f"
   },
   "source": [
    "Before feeding in the data,  we need to adapt our approach. We need to transform a continuous stream of time-stamped sensor data into fixed-size \"chunks\" (or windows) of readings. Each sequence becomes an input, and the label following the sequence becomes the output. This prepares the data for training an RNN model to recognise or predict activities over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568b65c",
   "metadata": {
    "executionInfo": {
     "elapsed": 18324,
     "status": "ok",
     "timestamp": 1746020873851,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "6568b65c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 7  # Set a random seed for reproducibility\n",
    "\n",
    "# Function to convert raw data into sequences for RNN training\n",
    "def create_sequences(data, seq_len=50):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Loop through the dataset to extract sequences\n",
    "    for i in range(len(data) - seq_len):\n",
    "        # Extract a sequence of `seq_len` rows from the selected features\n",
    "        sequence = data.iloc[i: i + seq_len][features].values\n",
    "\n",
    "        # The label is the activity immediately following the end of the sequence\n",
    "        label = data.iloc[i + seq_len]['Activity']\n",
    "\n",
    "        # Store the sequence and its label\n",
    "        X.append(sequence)\n",
    "        y.append(label)\n",
    "\n",
    "    # Return as NumPy arrays\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create input sequences and labels from the scaled dataframe\n",
    "X_seq, Y_seq = create_sequences(df_scaled, seq_len=50)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_seq, Y_seq,\n",
    "    test_size=0.2,             # 20% of the data used for testing\n",
    "    random_state=seed,         # Ensure the split is reproducible\n",
    "    stratify=Y_seq             # Preserve class distribution in the split\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32977c6",
   "metadata": {
    "id": "e32977c6"
   },
   "source": [
    "Let's visualise the sequences we have created, and plot the sensor data for a single sequence (e.g. the first one) to see how the signal evolves over time. This is especially useful in time-series data, where each feature (like `acc_x`, `acc_y`, `acc_z`, etc.) can reveal distinct motion patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98a965",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1746020874362,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "1c98a965",
    "outputId": "499fdb5f-1ccf-4fdc-8cd8-4a745cdd21e3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select our features\n",
    "features = ['acc_x', 'acc_y', 'acc_z']\n",
    "\n",
    "# Choose a sample sequence (e.g. the first one)\n",
    "sample_index = 0\n",
    "\n",
    "sequence = X_seq[sample_index]\n",
    "\n",
    "label = Y_seq[sample_index]\n",
    "\n",
    "# Map numeric label to a name\n",
    "label_map = {0: \"standing\", 1: \"walking\"}\n",
    "\n",
    "# Plot each feature in the sequence over time\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "for i, feature_name in enumerate(features):\n",
    "    plt.plot(sequence[:, i], label=feature_name)\n",
    "\n",
    "# Add vertical gridlines to emphasise time step boundaries between sequences (our chunks)\n",
    "for t in range(sequence.shape[0]):\n",
    "    plt.axvline(x=t, color='red', linestyle='--', linewidth=0.2)\n",
    "\n",
    "# Plot annotations and formatting\n",
    "plt.title(f\"Sensor readings for sequence {sample_index} — Label: {label_map[label]}\")\n",
    "\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Scaled sensor value\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0tOfxlVant7i",
   "metadata": {
    "id": "0tOfxlVant7i"
   },
   "source": [
    "From the plot, you can observe that `acc_y` shows pronounced fluctuations, as it captures vertical movement,the natural up-and-down motion of the body during walking or running. This makes it especially useful for detecting steps or gait patterns.\n",
    "\n",
    "The `acc_x` axis corresponds to lateral movement, such as swaying or shifting from side to side. This can be informative for identifying balance, stability, or side-stepping movements, which might appear in activities like turning or dancing.\n",
    "\n",
    "The `acc_z` axis captures forward and backward acceleration, the direction aligned with walking or running speed. It's particularly useful for identifying the intensity or speed of motion, as well as detecting starts and stops.\n",
    "\n",
    "Together, the three axes form a rich time series representation of full-body motion, and analysing their relative patterns can help distinguish between different types of activities, such as walking, standing, or climbing stairs. Features like frequency, amplitude, and variation across these axes often serve as key inputs to activity recognition models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d86183",
   "metadata": {},
   "source": [
    "### Model\n",
    "Our model performs binary sequence classification (for example, distinguishing “standing” from “walking”) by learning temporal dependencies directly from raw time-series inputs. It begins with a single SimpleRNN layer of 64 units, each using a ReLU activation to help the network ignore small fluctuations and concentrate on the most informative patterns across the `timesteps x features` input. As it processes each time step in the sequence, the RNN maintains an internal state that captures information from all preceding steps.\n",
    "\n",
    "Once the RNN has consumed the entire input sequence, its final hidden state, now a 64-dimensional summary of the observed time-series is fed into a Dense output layer with a sigmoid activation. This produces a probability between 0 and 1 for the positive class (e.g. “walking”). \n",
    "\n",
    "The model is compiled with the Adam optimiser to adjust its weights efficiently, and binary cross-entropy loss to penalise incorrect or over-confident predictions. During training, accuracy on a held-out validation set is monitored each epoch. \n",
    "\n",
    "Finally, after training for twenty epochs, the network is evaluated on the test data, yielding an overall test accuracy that reflects how well it generalises to new sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cc04a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147196,
     "status": "ok",
     "timestamp": 1746021021559,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "133cc04a",
    "outputId": "42cb4430-fc66-4890-fe8e-1b9e92014c93"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Increase epochs for this example.\n",
    "epochs = 20\n",
    "\n",
    "# Define a sequential model for binary classification (e.g. standing vs walking)\n",
    "model = Sequential([\n",
    "    # Recurrent layer with 64 units and ReLU activation\n",
    "    # It expects input shape: (timesteps, features)\n",
    "    SimpleRNN(64,\n",
    "              activation='relu',\n",
    "              input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "              ),\n",
    "\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    Dense(1, activation='sigmoid')  # Output is between 0 and 1 (binary class)\n",
    "])\n",
    "\n",
    "# Compile the model using binary crossentropy loss and accuracy as a metric\n",
    "model.compile(\n",
    "    optimizer='adam',                    # Adam optimiser adapts learning rate\n",
    "    loss='binary_crossentropy',         # Suitable for binary classification\n",
    "    metrics=['accuracy']                # Monitor classification accuracy\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "history_RNN = model.fit(\n",
    "    X_train,                            # Input features\n",
    "    Y_train,                            # Binary labels (e.g. 0 for standing, 1 for walking)\n",
    "    epochs=epochs,                      # Number of training epochs\n",
    "    validation_data=(X_test, Y_test)    # Validate on test set after each epoch\n",
    ")\n",
    "\n",
    "# Evaluate the trained model on the test data\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")      # Print test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9a7cd",
   "metadata": {},
   "source": [
    "Over the twenty epochs, the model achieved very high and stable performance on both the training and validation sets. In the first epoch it already reached around 97.6 % training accuracy with a loss of about 0.09, and validation accuracy of 98.2 % with a loss near 0.06. Although there were a few odd spikes in the training loss, most notably in epochs 3, 4 and 6, the validation metrics remained largely unaffected, suggesting the model was robust to these fluctuations.\n",
    "\n",
    "By the end of training, the network settled around 98.3 % validation accuracy with a validation loss of approximately 0.046, while final evaluation on the held-out test set gave 98.6 % accuracy and a loss of 0.041. The close alignment of training, validation and test accuracies, along with consistently low losses, indicates that the model both learned the underlying patterns effectively and generalised well to unseen data, which is what we want:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ifodDlptrqBS",
   "metadata": {
    "id": "ifodDlptrqBS"
   },
   "source": [
    "### Plot Train loss and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f0b47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1746021022116,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "762f0b47",
    "outputId": "d7689636-fea4-41c3-9658-a26d057f7322"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot the training loss (how much error the model made on the training data)\n",
    "plt.plot(history_RNN.history['loss'], label='Train Loss')\n",
    "\n",
    "# Plot the validation loss (how much error the model made on unseen validation data)\n",
    "plt.plot(history_RNN.history['val_loss'], label='Val Loss')\n",
    "\n",
    "plt.title('Loss over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Plot the training accuracy (how often the model got predictions right on training data)\n",
    "plt.plot(history_RNN.history['accuracy'], label='Train Accuracy')\n",
    "\n",
    "# Plot the validation accuracy (how often the model got predictions right on validation data)\n",
    "plt.plot(history_RNN.history['val_accuracy'], label='Val Accuracy')\n",
    "\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the layout so that the two plots don’t overlap or get squashed\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PZf4raEzsDSi",
   "metadata": {
    "id": "PZf4raEzsDSi"
   },
   "source": [
    "### Predict\n",
    "This next part of our code takes a single time-series example from our test set and checks exactly what our binary classifier thinks it represents. We pick out the 6th sample (`sample_index = 5`) and look up its true label (0 or 1) in a small dictionary that calls 0 for \"standing\" and 1 for \"walking\". Because the model expects a batch of inputs, we use `np.expand_dims` to turn our one-dimensional sequence into a batch of size one. Passing that through `model.predict` yields a single probability for the \"walking\" class. \n",
    "\n",
    "If we check whether that probability exceeds 0.5, we can decide on a final predicted label. Finally, we print out the true activity, the model’s guess in words, and the exact probability it assigned so we can judge not just whether it was right or wrong, but also how confident it was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7351baf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1746021022470,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "e7351baf",
    "outputId": "c6192385-ce7d-47b8-aa33-64abad7f6ebf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Choose a sample from the test set\n",
    "sample_index = 5\n",
    "\n",
    "# Map numeric label to a name\n",
    "label_map = {0: \"standing\", 1: \"walking\"}\n",
    "\n",
    "# Extract the sequence and true label\n",
    "sample_sequence = X_test[sample_index]\n",
    "\n",
    "true_label = int(Y_test[sample_index])\n",
    "\n",
    "# Reshape to match model input shape (batch size = 1)\n",
    "input_sequence = np.expand_dims(sample_sequence, axis=0)\n",
    "\n",
    "# Predict probability of class 1 (e.g., walking)\n",
    "prediction_prob = model.predict(input_sequence)[0][0]\n",
    "\n",
    "# Convert to binary prediction\n",
    "predicted_label = int(prediction_prob > 0.5)\n",
    "\n",
    "# Map numeric labels to names\n",
    "true_label_name = label_map[true_label]\n",
    "predicted_label_name = label_map[predicted_label]\n",
    "\n",
    "# Display result\n",
    "print(f\"True Label: {true_label_name}\")\n",
    "print(f\"Predicted Label: {predicted_label_name}\")\n",
    "print(f\"Predicted Probability: {prediction_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f43e5",
   "metadata": {},
   "source": [
    "This next part of our code visualises the raw sensor signals for a single example alongside the model’s verdict. It loops over the three accelerometer axes: `acc_x`, `acc_y` and `acc_z`, and plots each as a time-series on the same figure, so we can see how the motion evolves step by step. \n",
    "\n",
    "The chart reports the true activity (standing or walking), the model’s predicted label, and the confidence (the probability it assigned to \"walking\"). By labelling the axes (\"Time step\" on the x-axis and \"Scaled sensor value\" on the y-axis). This allows us to view the input data and how our classifier interpreted it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xCxlUhyS97Z_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1746021022854,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "xCxlUhyS97Z_",
    "outputId": "8c138b6a-f562-4ab4-bcd7-d6f2a89d9115"
   },
   "outputs": [],
   "source": [
    "# Plot the sequence of sensor readings (e.g. from accelerometer) and show the predicted label\n",
    "features = ['acc_x', 'acc_y', 'acc_z']  # Names of the 3 input features\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Loop through each feature and plot it over time\n",
    "for i, feature_name in enumerate(features):\n",
    "    plt.plot(sample_sequence[:, i], label=feature_name)  # Plot i-th feature (e.g. acc_x)\n",
    "\n",
    "plt.title(f\"Sequence {sample_index} — True: {true_label_name} | Predicted: {predicted_label_name} ({prediction_prob:.2f})\")\n",
    "\n",
    "plt.xlabel(\"Time step\")                   # Each point represents one time step\n",
    "plt.ylabel(\"Scaled sensor value\")         # Sensor values are usually normalised\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Ensure layout elements don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab940b4e",
   "metadata": {
    "id": "ab940b4e"
   },
   "source": [
    "### Long Short-Term Memory (LSTM)\n",
    "\n",
    "An *LSTM*, or Long Short-Term Memory network, is a special kind of *Recurrent Neural Network (RNN)* designed to remember information over longer sequences. In a basic RNN, the model processes inputs one step at a time. For example, reading a sentence word by word, or a signal one value at a time, but it tends to \"forget\" earlier inputs as the sequence gets longer. This is called the *vanishing gradient problem*, and it's a key limitation of simple RNNs.\n",
    "\n",
    "LSTMs solve this problem by introducing a more sophisticated internal structure made up of *gates*:\n",
    "- The *input gate* controls how much new information should be stored,\n",
    "- The *forget gate* decides what information to discard from memory,\n",
    "- And the *output gate* controls what gets passed to the next layer or time step.\n",
    "\n",
    "These gates help the LSTM keep useful information for a much longer time, making it especially powerful for tasks where understanding *context over time* really matters, such as language modelling, machine translation, speech recognition, or time series forecasting.\n",
    "\n",
    "In short, moving from an RNN to an LSTM gives us a more powerful, more memory-aware version of the same idea, without needing to change the input format at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HzWdq0VRpDTy",
   "metadata": {
    "id": "HzWdq0VRpDTy"
   },
   "source": [
    "### Air passenger dataset\n",
    "The *Airline Passengers* dataset is a widely used and well-known time series dataset that records the monthly number of international airline passengers from January 1949 to December 1960. It is often used in teaching, research, and practical demonstrations of time series forecasting models, due to its clear structure and interesting temporal patterns.\n",
    "\n",
    "The dataset consists of two columns: the first is the *month*, formatted as `YYYY-MM`, and the second is the *number of passengers* (in thousands) recorded during that month. With 144 data points in total, it provides just enough historical context to explore long-term trends while being small enough to process efficiently in most environments.\n",
    "\n",
    "One of the most striking characteristics of the data is the presence of both a *trend* and *seasonality*. Over the years, the number of passengers steadily increases, reflecting the growth of air travel in the post-war period. At the same time, there are consistent seasonal peaks and troughs, typically with higher passenger numbers during mid-year months, making the dataset ideal for illustrating techniques that detect or model seasonal behaviour.\n",
    "\n",
    "Because of its structure and historical nature, the Airline Passengers dataset is frequently used to introduce models like *ARIMA*, *exponential smoothing*, and our *LSTM neural network*. It provides a clean and interpretable context for learning about data preparation (e.g. lag features, windowing), visualisation, and forecasting performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbtDNoAJsOP0",
   "metadata": {
    "id": "sbtDNoAJsOP0"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0db0fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746021022862,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "fe0db0fa",
    "outputId": "19b322c4-d848-4f5c-d084-bf43ee863ed9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load monthly airline passenger totals (1949–1960) from a public dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uLjscG1cpuLZ",
   "metadata": {
    "id": "uLjscG1cpuLZ"
   },
   "source": [
    "### Preprocessing\n",
    "We use `MinMaxScaler` to scale the data to a range between 0 and 1. This is particularly important for models like LSTMs or neural networks, which are sensitive to the scale of input data. Without scaling, large input values could cause unstable learning, or very slow convergence due to imbalanced gradient updates (more on this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZIMNJKYBlFW",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746021022877,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "sZIMNJKYBlFW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Convert column to float and reshape\n",
    "data = df['Passengers'].values.astype(float).reshape(-1, 1)\n",
    "\n",
    "# Normalize to [0, 1] range\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YCpkGVtVqRo6",
   "metadata": {
    "id": "YCpkGVtVqRo6"
   },
   "source": [
    "The `create_sequences` function is designed to transform a continuous time series into a structured format suitable for training machine learning models, particularly those that handle sequential data, like Recurrent Neural Networks (RNNs) or Long Short-Term Memory networks (LSTMs). Time series data on its own is just a long sequence of values, but to use it for prediction, we need to frame it as a supervised learning problem: using past values to predict future ones. This function accomplishes exactly that.\n",
    "\n",
    "We will write another function that will implement a sliding window over the data. For each position in the sequence, it will take a fixed number of previous time steps. For example, the past 10 months and store that as one input sample (`X`). The value that comes immediately after that sequence becomes the target output (`y`) for that sample. This way, the model learns from each short history of past values and is trained to predict what comes next. This approach is known as *sequence-to-one prediction*, where a window of time steps is mapped to a single future value.\n",
    "\n",
    "Using this format, we can generate hundreds of training examples from a relatively short time series. These overlapping sequences capture local patterns in the data, such as seasonal trends or repeating shapes in the curve. This is especially important for neural networks, which learn by recognising patterns across samples. Without this kind of preprocessing, a model would have no context about the structure of the time series and would be unable to make informed predictions.\n",
    "\n",
    "Ultimately, this preparation step makes time series forecasting possible with deep learning models. It reshapes the raw time series into a set of training inputs (`X`) and targets (`y`), where each input is a 2D array of shape `(sequence_length, 1)` and each target is the next time step. This structure is exactly what RNNs and LSTMs are designed to work with, allowing them to learn from the temporal dynamics in the data.\n",
    "\n",
    "We create a function `create_sequences` for this purpose, which takes the data and a set size for the sequence and converts the data to sequence data and the target labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OcpA44JFBoRL",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746021022879,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "OcpA44JFBoRL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to transform a 1D array of data into overlapping sequences\n",
    "# and corresponding next-step targets for sequence prediction tasks\n",
    "def create_sequences(data, seq_length=10):\n",
    "    X, y = [], []  # Initialise lists to hold input sequences and labels\n",
    "    \n",
    "    # Loop over the data, stopping seq_length elements before the end\n",
    "    for i in range(len(data) - seq_length):\n",
    "\n",
    "        # Extract a window of length seq_length as the input sequence\n",
    "        X.append(data[i:i + seq_length])\n",
    "\n",
    "        # The label is the item immediately following the input window\n",
    "        y.append(data[i + seq_length])\n",
    "    \n",
    "    # Convert lists to NumPy arrays for compatibility with ML frameworks\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_sequences(data_scaled, seq_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TCQ2xIJdrHdr",
   "metadata": {
    "id": "TCQ2xIJdrHdr"
   },
   "source": [
    "### Resampling\n",
    "As always, start by splitting our data into train and test sets. We will apply a simple technique rather than import a library like `train_test_split` (for demonstration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCBuhAbEBqKK",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1746021022889,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "TCBuhAbEBqKK"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a27ed2",
   "metadata": {},
   "source": [
    "### Model\n",
    "This model is built to forecast the next value in a univariate time-series (monthly passenger counts) by learning temporal patterns from fixed-length input windows. It begins with an input layer that expects sequences of shape `(timesteps, features)`, in this case ten months of data with one feature per month.\n",
    "\n",
    "The core layer is a single LSTM with 64 units and ReLU activation, which helps the network focus on meaningful trends and ignore small fluctuations that look like noise, while retaining information from earlier time-steps. \n",
    "\n",
    "After processing the entire ten-step sequence the LSTM produces a 64-dimensional summary of recent behaviour, which is then passed to a dense output layer with one neuron to generate the forecast for month eleven. \n",
    "\n",
    "The model is trained using the Adam optimiser to minimise mean squared error, running for fifty epochs with batches of sixteen sequences and validating on a held-out test set to monitor generalisation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tMrrl9FuBrlx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17048,
     "status": "ok",
     "timestamp": 1746021039937,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "tMrrl9FuBrlx",
    "outputId": "3b3f588b-34cf-4ccc-bf8f-ecc606455dee"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Increase epochs for this example.\n",
    "epochs = 50\n",
    "\n",
    "# Create a Sequential model, which lets us stack layers one after another\n",
    "model = Sequential([\n",
    "    # Input layer specifying the shape of each training example\n",
    "    # Each example is a sequence of time steps (10 months), with 1 feature (passenger count)\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "\n",
    "    # LSTM layer with 64 units (or \"neurons\"), designed to learn patterns across time\n",
    "    # LSTMs are good at remembering information from earlier in the sequence\n",
    "    # activation='relu' helps the network focus on useful signals and ignore noise\n",
    "    LSTM(64, activation='relu'),\n",
    "\n",
    "    # Output layer with a single neuron for predicting the next value in the sequence\n",
    "    # No activation function here since we're predicting a number (regression task)\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model: specify how it should learn\n",
    "# 'adam' is an optimiser that helps the model improve efficiently\n",
    "# 'mse' (mean squared error) is the loss function, measuring how far off the predictions are\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='mse', \n",
    "    metrics=['mae']                # Monitor MAE\n",
    ")\n",
    "\n",
    "# Train the model using the training data\n",
    "# epochs = how many times the model sees the full dataset\n",
    "# batch_size = how many sequences it looks at before updating its learning\n",
    "# validation_data = a separate set used to monitor how well it's generalising\n",
    "history_LSTM = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test, Y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358653d0",
   "metadata": {},
   "source": [
    "Over the fifty epochs, the model’s mean absolute error on the training set fell dramatically from about 0.27 in epoch 1 to roughly 0.06 by epoch 50, showing that it was learning to predict the next value very precisely. \n",
    "\n",
    "On the validation set the MAE started around 0.52, plummeted to about 0.12 by epoch 4, and then continued a gentle downward trend, reaching approximately 0.11 by the final epoch. Because the training and validation MAE curves both drop in step and remain close throughout, there’s no sign of serious over-fitting, and the model achieves a low validation error of around 0.11. \n",
    "\n",
    "In practice you might stop once the validation MAE bottoms out, around epoch 40 or so, to save time, but overall the network converges cleanly to accurate, generalisable predictions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KK4lf9t8rSrS",
   "metadata": {
    "id": "KK4lf9t8rSrS"
   },
   "source": [
    "### Plot Train loss and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bE01CwTBu64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1746021040133,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "2bE01CwTBu64",
    "outputId": "51af12c8-3f93-47e2-fdb2-f923b55634a4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot the training loss (how much error the model made on the training data)\n",
    "plt.plot(history_LSTM.history['loss'], label='Train Loss')\n",
    "\n",
    "# Plot the validation loss (how much error the model made on unseen validation data)\n",
    "plt.plot(history_LSTM.history['val_loss'], label='Val Loss')\n",
    "\n",
    "plt.title('Loss over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Plot the training `accuracy` (how often the model got predictions right on training data)\n",
    "plt.plot(history_LSTM.history['mae'], label='Train MAE')\n",
    "\n",
    "# Plot the validation `accuracy` (how often the model got predictions right on validation data)\n",
    "plt.plot(history_LSTM.history['val_mae'], label='Val MAE')\n",
    "\n",
    "plt.title('MAE over Epochs')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the layout so that the two plots don’t overlap or get squashed\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OEmjZh8DsU5x",
   "metadata": {
    "id": "OEmjZh8DsU5x"
   },
   "source": [
    "### Predict\n",
    "Here we take the trained LSTM model and use it to forecast passenger counts on our test sequences. First, `model.predict(X_test)` generates a sequence of scaled predictions. Because the model was trained on normalised data, we then apply `scaler.inverse_transform` to both the predictions and the true test targets (`Y_test`) to convert them back into the original passenger‐count units. \n",
    "\n",
    "Finally, we plot both the actual passenger numbers and the model’s forecasts on the same axes labelled \"True Values\" and \"Predictions\" with time steps along the x‐axis and passenger counts on the y‐axis. \n",
    "\n",
    "The resulting line chart gives you a clear visual comparison of how closely the model’s predictions track the real data over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YalFNG5DBwu7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1746021040499,
     "user": {
      "displayName": "Martyn Harris",
      "userId": "17134958627456907188"
     },
     "user_tz": -60
    },
    "id": "YalFNG5DBwu7",
    "outputId": "3fba2571-72fe-40fe-ccc6-7494005c6a2b"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scale predictions\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "y_test_inv = scaler.inverse_transform(Y_test)\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.plot(y_test_inv, label='True Values')\n",
    "plt.plot(y_pred_inv, label='Predictions')\n",
    "\n",
    "plt.title(\"Airline Passenger Forecasting\")\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be293f9a",
   "metadata": {
    "id": "be293f9a"
   },
   "source": [
    "### Summarising models\n",
    "Once we’ve trained multiple models, such as the Perceptron, Feedforward Neural Network (FNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM).  It’s important to go back and compare how well they perform. One of the most common ways to do this is by plotting *validation accuracy* over time as we have seen.\n",
    "\n",
    "Validation accuracy tells us how well the model performs on data it hasn’t seen during training. Plotting this over each *epoch* (a complete pass through the training data), allows us to see whether the model is improving, plateauing, or even starting to overfit.\n",
    "\n",
    "Visual comparison helps us answer questions like:\n",
    "- Which model learns the fastest?\n",
    "- Which one achieves the highest accuracy?\n",
    "- Do any models overfit (perform well on training but poorly on validation)?\n",
    "- Is the extra complexity (e.g. using an LSTM) actually leading to better results?\n",
    "\n",
    "In short, we get a clearer picture of how each model is learning, which helps us choose the best one for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515c35e",
   "metadata": {
    "id": "b515c35e"
   },
   "source": [
    "### What have we learnt?\n",
    "We explored the foundations of deep learning by training and comparing four different types of neural networks: the *Perceptron*, *Feedforward Neural Network (FNN)*, *Recurrent Neural Network (RNN)*, and *Long Short-Term Memory (LSTM)* model. We used a variety of different datasets and chose the most appropriate model to suit the data and the task.\n",
    "\n",
    "We also learned how to evaluate the performance of these models. The main metric we focused on was *accuracy*, which tells us what percentage of the predictions were correct.\n",
    "\n",
    "By now, you should have a clear understanding of how different neural network architectures behave, how to evaluate them properly, and how to swap in different types of data to experiment further. This sets the foundation for building more advanced and task-specific deep learning models.\n",
    "\n",
    "Try changing the architecture, playing with different types of input data, or tuning model parameters and observe how these changes affect your results. This kind of hands-on experimentation is the best way to deepen your understanding of machine learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "name": "Neural_Network_Models_Evaluation_And_Normalisation_British.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
